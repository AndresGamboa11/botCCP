# ingest/ingest_ccp.py
import os
import logging
from pathlib import Path
from typing import List, Tuple

from dotenv import load_dotenv, find_dotenv
from fastembed import TextEmbedding
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGGING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
log = logging.getLogger("ingest_ccp")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Carga .env (solo si existe)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_dotenv = find_dotenv(usecwd=True)
if _dotenv:
    load_dotenv(_dotenv, override=False)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ENV
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
QDRANT_URL        = (os.getenv("QDRANT_URL") or "").strip()
QDRANT_API_KEY    = (os.getenv("QDRANT_API_KEY") or "").strip()
QDRANT_COLLECTION = (os.getenv("QDRANT_COLLECTION") or "ccp_docs").strip()

# Modelo preferido (por ti) â€“ puede o no estar soportado por FastEmbed
EMBED_MODEL_ENV   = (os.getenv("HF_EMBED_MODEL") or "intfloat/multilingual-e5-small").strip()

# Archivo de conocimiento
KNOW_FILE_ENV     = (os.getenv("CCP_KNOW_FILE") or "knowledge/CCPAMPLONA.md").strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utilidades
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resolve_knowledge_path() -> Path:
    base_dir = Path(__file__).resolve().parents[1]  # carpeta raÃ­z del proyecto
    path = Path(KNOW_FILE_ENV)
    if not path.is_absolute():
        path = base_dir / path
    return path


def read_markdown_chunks(path: Path, max_chars: int = 600) -> List[str]:
    """
    Lee un archivo .md y lo divide en fragmentos de tamaÃ±o razonable.
    """
    if not path.exists():
        raise FileNotFoundError(f"No se encontrÃ³ el archivo de conocimiento: {path}")

    log.info(f"ğŸ“„ Leyendo archivo: {path}")

    text = path.read_text(encoding="utf-8", errors="ignore")

    # Dividir por bloques separados por lÃ­neas en blanco
    raw_blocks = [b.strip() for b in text.split("\n\n") if b.strip()]

    chunks: List[str] = []
    for block in raw_blocks:
        if len(block) <= max_chars:
            chunks.append(block)
        else:
            # Si el bloque es muy grande, cortarlo en trozos
            start = 0
            while start < len(block):
                end = start + max_chars
                chunks.append(block[start:end])
                start = end

    log.info(f"âœ… Fragmentos: {len(chunks)}")
    return chunks


def _normalize_supported_models(raw_supported) -> List[str]:
    """
    Convierte lo que devuelva FastEmbed (str / dict / objeto raro)
    a una lista de nombres de modelo (str).
    """
    names: List[str] = []
    for m in raw_supported:
        if isinstance(m, str):
            names.append(m)
        elif isinstance(m, dict):
            # FastEmbed suele usar claves tipo "model" o "name"
            name = m.get("model") or m.get("name") or m.get("id")
            if name:
                names.append(str(name))
        else:
            # Ãšltimo recurso: cast a string
            names.append(str(m))
    # Eliminar duplicados conservando orden
    seen = set()
    unique: List[str] = []
    for n in names:
        if n not in seen:
            seen.add(n)
            unique.append(n)
    return unique


def create_embedder_with_fallback(preferred_model: str) -> Tuple[TextEmbedding, str]:
    """
    Crea un TextEmbedding usando un modelo soportado por FastEmbed.
    - Intenta primero el modelo indicado en .env (si estÃ¡ en los soportados).
    - Luego una lista de modelos recomendados.
    - Luego recurre a cualquiera de los soportados.
    """
    raw_supported = TextEmbedding.list_supported_models()
    supported_names = _normalize_supported_models(raw_supported)

    log.info("ğŸ§  Modelos soportados por FastEmbed:")
    for n in supported_names:
        log.info(f"   â€¢ {n}")

    candidates: List[str] = []

    # 1) Modelo que pusiste en .env
    if preferred_model:
        candidates.append(preferred_model)

    # 2) Modelos recomendados (multilingÃ¼e + algunos comunes)
    for m in (
        "intfloat/multilingual-e5-base",
        "sentence-transformers/all-MiniLM-L6-v2",
        "BAAI/bge-small-en-v1.5",
    ):
        if m not in candidates:
            candidates.append(m)

    # 3) AÃ±adir todos los soportados como Ãºltimos candidatos
    for n in supported_names:
        if n not in candidates:
            candidates.append(n)

    last_err: Exception | None = None

    for name in candidates:
        # Si tenemos lista de soportados, filtramos por ella
        if supported_names and name not in supported_names:
            log.warning(f"âš  Modelo '{name}' no estÃ¡ en la lista soportada de FastEmbed. Se omite.")
            continue
        try:
            log.info(f"ğŸ§  Cargando modelo FastEmbed: {name}")
            embedder = TextEmbedding(model_name=name)
            log.info(f"âœ… Usando modelo de embeddings: {name}")
            return embedder, name
        except Exception as e:
            last_err = e
            log.warning(f"âš  No se pudo inicializar modelo '{name}': {e}")

    raise RuntimeError(
        f"No se pudo inicializar ningÃºn modelo de embeddings. Ãšltimo error: {last_err}"
    )


def ensure_qdrant_collection(
    client: QdrantClient,
    collection_name: str,
    vector_size: int,
    distance: qmodels.Distance = qmodels.Distance.COSINE,
):
    """
    Crea (o recrea) la colecciÃ³n en Qdrant con el tamaÃ±o de vector correcto.
    """
    log.info(f"ğŸ—ƒï¸ Asegurando colecciÃ³n Qdrant '{collection_name}' (dim: {vector_size})")

    try:
        client.get_collection(collection_name)
        # Si existe, la recreamos para limpiar datos antiguos:
        log.info(f"ğŸ” ColecciÃ³n '{collection_name}' ya existe, se recrearÃ¡.")
        client.recreate_collection(
            collection_name=collection_name,
            vectors_config=qmodels.VectorParams(size=vector_size, distance=distance),
        )
    except Exception:
        log.info(f"ğŸ“¦ Creando colecciÃ³n nueva '{collection_name}'")
        client.recreate_collection(
            collection_name=collection_name,
            vectors_config=qmodels.VectorParams(size=vector_size, distance=distance),
        )


def upload_documents_to_qdrant(
    client: QdrantClient,
    collection_name: str,
    chunks: List[str],
    vectors: List[List[float]],
    source_name: str,
    batch_size: int = 64,
):
    """
    Sube los textos y sus vectores a Qdrant.
    """
    if len(chunks) != len(vectors):
        raise ValueError(
            f"NÃºmero de textos ({len(chunks)}) y vectores ({len(vectors)}) no coincide."
        )

    log.info(f"ğŸš€ Subiendo {len(chunks)} puntos a Qdrant (batch_size={batch_size})")

    points: List[qmodels.PointStruct] = []
    for idx, (text, vector) in enumerate(zip(chunks, vectors)):
        payload = {
            "text": text,
            "source": source_name,
            "index": idx,
        }
        points.append(
            qmodels.PointStruct(
                id=idx,
                vector=vector,
                payload=payload,
            )
        )

    client.upload_points(
        collection_name=collection_name,
        points=points,
        batch_size=batch_size,
    )

    log.info("âœ… Ingesta completada y subida a Qdrant.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # Debug de config
    print(f"ğŸ” DEBUG QDRANT_URL      : {QDRANT_URL}")
    print(f"ğŸ” DEBUG QDRANT_COLLECTION: {QDRANT_COLLECTION}")
    print(f"ğŸ” DEBUG EMBED_MODEL_ENV  : {EMBED_MODEL_ENV}")

    if not QDRANT_URL:
        raise RuntimeError("QDRANT_URL no estÃ¡ definido en el entorno (.env).")
    if not QDRANT_COLLECTION:
        raise RuntimeError("QDRANT_COLLECTION no estÃ¡ definido en el entorno (.env).")

    knowledge_path = resolve_knowledge_path()
    chunks = read_markdown_chunks(knowledge_path, max_chars=600)

    # Crear embedder con fallback robusto
    embedder, used_model = create_embedder_with_fallback(EMBED_MODEL_ENV)
    print(f"ğŸ§  Modelo de embeddings FINAL: {used_model}")

    # Generar embeddings
    log.info("ğŸ§  Generando embeddings con FastEmbed...")
    vectors: List[List[float]] = []
    for emb in embedder.embed(chunks):
        vectors.append(list(emb))

    if not vectors:
        raise RuntimeError("No se generaron vectores de embeddings (lista vacÃ­a).")

    dim = len(vectors[0])
    log.info(f"ğŸ“ DimensiÃ³n de vector: {dim}")

    # Conectar a Qdrant
    client = QdrantClient(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY or None,
        prefer_grpc=False,
    )

    # Asegurar colecciÃ³n
    ensure_qdrant_collection(client, QDRANT_COLLECTION, dim)

    # Subir datos
    upload_documents_to_qdrant(
        client=client,
        collection_name=QDRANT_COLLECTION,
        chunks=chunks,
        vectors=vectors,
        source_name=knowledge_path.name,
        batch_size=64,
    )

    print("ğŸ‰ Ingesta finalizada correctamente.")


if __name__ == "__main__":
    main()
